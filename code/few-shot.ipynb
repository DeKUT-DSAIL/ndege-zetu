{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "835421b1-532c-407d-be41-e689bb493a67",
   "metadata": {},
   "source": [
    "# Few Shot Learning\n",
    "\n",
    "We also examine the impact of the number of training examples on classification performance. The number of training examples\n",
    "was varied from 2 to 10 in steps of 2 and the AUC evaluated for 100 training runs. In each case the rest of the class examples were\n",
    "included in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e36e5c-aed7-437f-ba8a-578b581add0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a67d8a1-3e46-4b35-b9a2-8380a41f49cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed for reproducability\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c26c5d8-c7db-4166-a244-61a7ecd87196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_indices(labels, num_train, sps):\n",
    "\n",
    "    labels_array = np.array(labels)\n",
    "    indices = np.arange(len(labels))\n",
    "    \n",
    "    train_indices = np.array([])\n",
    "    test_indices = np.array([])\n",
    "    for sp in sps:\n",
    "        sp_indices = indices[labels_array == sp]\n",
    "        train_indx, test_indx = train_test_split(sp_indices, train_size=num_train, shuffle=True)\n",
    "    \n",
    "        if train_indices.size:\n",
    "            train_indices = np.concatenate((train_indices, train_indx))\n",
    "        else:\n",
    "            train_indices = train_indx\n",
    "    \n",
    "        if test_indices.size:\n",
    "            test_indices = np.concatenate((test_indices, test_indx))\n",
    "        else:\n",
    "            test_indices = test_indx\n",
    "\n",
    "    train_indices.sort()\n",
    "    test_indices.sort()\n",
    "\n",
    "    return train_indices, test_indices\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd10903e-eafb-485b-b2f9-c7367680be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dir = '../embeddings/'\n",
    "embedding_files = os.listdir(embeddings_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34309b5d-b013-4375-8a50-174833625c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../annotations/single_species_filenames.json', 'r') as fp:\n",
    "    single_species_filenames = json.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56315092-b71f-4259-9440-50c957ec3f2b",
   "metadata": {},
   "source": [
    "## Features and labels\n",
    "\n",
    "The 1280 dimensional embeddings are extracted from each of the 12 five second segments from the 1\n",
    "minute long recordings and the mean of these embeddings are used as a feature for the recording.\n",
    "\n",
    "We use species with more than 10 recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92c89a2a-1930-4a85-874e-fdfe9ca8c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "mean_embeddings = np.array([])\n",
    "single_species_embedding_files = [ef for ef in embedding_files if ef.replace('npz', 'mp3') in single_species_filenames.keys()]\n",
    "for embedding_file in single_species_embedding_files:\n",
    "    labels.append(single_species_filenames[embedding_file.replace('npz', 'mp3')])\n",
    "    npzfile = np.load(os.path.join(embeddings_dir, embedding_file))\n",
    "    file_embeddings = npzfile['embeddings']\n",
    "\n",
    "    if mean_embeddings.size:\n",
    "        mean_embeddings = np.vstack((mean_embeddings, np.mean(file_embeddings, 0)))\n",
    "    else:\n",
    "        mean_embeddings = np.mean(file_embeddings, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d175d148-c634-4935-852a-d90c74ebee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_indices = label_encoder.fit_transform(labels)\n",
    "\n",
    "label_counts = Counter(labels)\n",
    "threshold = 10\n",
    "\n",
    "filtered_labels = [label for label, count in label_counts.items() if count >= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72701ce0-688f-48b4-ac0e-a40bcb3bb6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = []\n",
    "for label in labels:\n",
    "    if label in filtered_labels:\n",
    "        new_labels.append(label)\n",
    "    else:\n",
    "        new_labels.append('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9214fae4-ec83-4574-8cb6-2218f33174be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sps = Counter(new_labels).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3af936-81ce-4051-9dbf-8e3c92262d9f",
   "metadata": {},
   "source": [
    "### Few shot learning\n",
    "We vary the number of training examples from 2 to 10 in steps of two and perform 100 runs each. We plot boxplots of AUC and accuracy as a function of number of traing examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c044f37-e228-466b-a86c-1368b722cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trial = 100\n",
    "np.random.seed(123)\n",
    "classifier = LogisticRegression(max_iter=500)\n",
    "\n",
    "num_train_auc = []\n",
    "num_train_acc = []\n",
    "\n",
    "for num_train in range(2, 11, 2):\n",
    "    lr_auc = []\n",
    "    lr_acc = []\n",
    "    for trial in range(num_trial):    \n",
    "        train_indices, test_indices = train_test_indices(new_labels, num_train, sps)\n",
    "\n",
    "        X_train = mean_embeddings[train_indices,:]\n",
    "        X_test = mean_embeddings[test_indices,:]\n",
    "\n",
    "        y_train = [label for indx, label in enumerate(new_labels) if indx in train_indices] \n",
    "        y_test = [label for indx, label in enumerate(new_labels) if indx in test_indices]\n",
    "\n",
    "        y_score = classifier.fit(X_train, y_train).predict_proba(X_test)\n",
    "\n",
    "        macro_roc_auc_ovr = roc_auc_score(\n",
    "            y_test,\n",
    "            y_score,\n",
    "            multi_class=\"ovr\",\n",
    "            average=\"macro\",\n",
    "        )\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        lr_auc.append(macro_roc_auc_ovr)\n",
    "        lr_acc.append(accuracy)\n",
    "    num_train_acc.append(lr_acc)\n",
    "    num_train_auc.append(lr_auc)\n",
    "                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afdcd62-9448-4f82-b6d0-57607b9c6c9a",
   "metadata": {},
   "source": [
    "## Figure 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c114836-e95b-413b-bfa5-a68ea8b2cc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(np.array(num_train_auc).T);\n",
    "plt.xticks([1,2,3,4,5], [2,4,6,8,10]);\n",
    "plt.xlabel('Number of Training Examples')\n",
    "plt.ylabel('AUC')\n",
    "plt.savefig('few-shot-auc.jpg', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba049c-44fd-4326-bf07-787c31617afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(np.array(num_train_acc).T);\n",
    "plt.xticks([1,2,3,4,5], [2,4,6,8,10]);\n",
    "plt.xlabel('Number of Training Examples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('few-shot-acc.jpg', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
